\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}


\usepackage{longtable,booktabs}
\usepackage{graphicx}
% grffile has become a legacy package: https://ctan.org/pkg/grffile
\IfFileExists{grffile.sty}{%
\usepackage{grffile}
}{}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

\RequirePackage[]{C:/Users/liche/Documents/R/win-library/4.0/BiocStyle/resources/tex/Bioconductor}

\bioctitle[]{NetID User Guide}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
\author{Ziyang Chen}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{22 四月 2021}

% code highlighting
\definecolor{fgcolor}{rgb}{0.251, 0.251, 0.251}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.816,0.125,0.439}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.251,0.627,0.251}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.502,0.502,0.502}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.251,0.251,0.251}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.125,0.125,0.941}{#1}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.251,0.251,0.251}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.878,0.439,0.125}{#1}}%
\let\hlipl\hlkwb
%
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
%
\newenvironment{Shaded}{\begin{myshaded}}{\end{myshaded}}
% set background for result chunks
\let\oldverbatim\verbatim
\renewenvironment{verbatim}{\color{codecolor}\begin{myshaded}\begin{oldverbatim}}{\end{oldverbatim}\end{myshaded}}
%
\newcommand{\KeywordTok}[1]{\hlkwd{#1}}
\newcommand{\DataTypeTok}[1]{\hlkwc{#1}}
\newcommand{\DecValTok}[1]{\hlnum{#1}}
\newcommand{\BaseNTok}[1]{\hlnum{#1}}
\newcommand{\FloatTok}[1]{\hlnum{#1}}
\newcommand{\ConstantTok}[1]{\hlnum{#1}}
\newcommand{\CharTok}[1]{\hlstr{#1}}
\newcommand{\SpecialCharTok}[1]{\hlstr{#1}}
\newcommand{\StringTok}[1]{\hlstr{#1}}
\newcommand{\VerbatimStringTok}[1]{\hlstr{#1}}
\newcommand{\SpecialStringTok}[1]{\hlstr{#1}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\hlcom{#1}}
\newcommand{\DocumentationTok}[1]{\hlcom{#1}}
\newcommand{\AnnotationTok}[1]{\hlcom{#1}}
\newcommand{\CommentVarTok}[1]{\hlcom{#1}}
\newcommand{\OtherTok}[1]{{#1}}
\newcommand{\FunctionTok}[1]{\hlstd{#1}}
\newcommand{\VariableTok}[1]{\hlstd{#1}}
\newcommand{\ControlFlowTok}[1]{\hlkwd{#1}}
\newcommand{\OperatorTok}[1]{\hlopt{#1}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textit{#1}}
\newcommand{\AttributeTok}[1]{{#1}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor{messagecolor}{#1}}
\newcommand{\WarningTok}[1]{\textcolor{warningcolor}{#1}}
\newcommand{\AlertTok}[1]{\textcolor{errorcolor}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor{errorcolor}{#1}}
\newcommand{\NormalTok}[1]{\hlstd{#1}}
%
\AtBeginDocument{\bibliographystyle{C:/Users/liche/Documents/R/win-library/4.0/BiocStyle/resources/tex/unsrturl}}


\begin{document}
\maketitle


{
\setcounter{tocdepth}{2}
\tableofcontents
\newpage
}
\hypertarget{enviroment-setup}{%
\section{Enviroment Setup}\label{enviroment-setup}}

This section provides step-by-step instructions to set up the environment to run NetID algorithm in a local computer. A Windows system is recommended. Typical install time on a ``normal'' desktop computer is within a few hours.

\hypertarget{software-installation}{%
\subsection{Software installation}\label{software-installation}}

\begin{itemize}
\item
  Install R, Rstudio, Rtools40, ILOG CPLEX Optimization Studio (CPLEX), preferably at default location.

  \begin{quote}
  \textbf{R}(4.0.3): \url{https://www.r-project.org/}\\
  \textbf{RStudio}: \url{https://rstudio.com/products/rstudio/download}\\
  \textbf{Rtools40}: \url{https://cran.r-project.org/bin/windows/Rtools/ow}\\
  \textbf{CPLEX}(12.10): \url{https://www.ibm.com/academic/technology/data-science}
  \end{quote}
\item
  You need to add R and Rtools40 to Environmental Variables PATH, with instruction provided at the end.
\end{itemize}

\hypertarget{code-download}{%
\subsection{Code download}\label{code-download}}

\hypertarget{via-git-recommended}{%
\subsubsection{Via Git (recommended)}\label{via-git-recommended}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Install \textbf{git} via \url{https://support.rstudio.com/hc/en-us/articles/200532077?version=1.3.1093\&mode=desktop}
\item
  In Rstudio, go to \texttt{File} \(\rightarrow\) \texttt{New project} \(\rightarrow\) \texttt{Version control} \(\rightarrow\) \texttt{Git}, enter \url{https://github.com/LiChenPU/NetID.git} for \texttt{URL}, select a subdirectory, and create project.
\item
  You should be able to see all files in place under your selected subdirectory. Use pull option to check for latest updates.
\end{enumerate}

\hypertarget{via-github}{%
\subsubsection{Via Github}\label{via-github}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Go to website \url{https://github.com/LiChenPU/NetID}, hit the green \texttt{code} button, select download zip, and unzip files.
\end{enumerate}

\hypertarget{package-dependency-installation}{%
\subsection{Package dependency installation}\label{package-dependency-installation}}

Most of the dependent packages can be installed by running the R script NetID\_packages.R in the \texttt{get started} folder. See \textbf{Troubleshooting} section for possible errors.

The package, \textbf{cplexAPI}, connecting R to CPLEX, requires additional installation steps.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Go to website: \url{https://cran.r-project.org/web/packages/cplexAPI/index.html}, look for \texttt{Package source}, and download \texttt{cplexAPI\_1.4.0.tar.gz}. In the same page, look for \texttt{Materials}, and open the \texttt{INSTALL link}
\item
  Unzip the folder \texttt{cplexAPI} to the \textbf{desktop}, follow the installation guide to modify the file \texttt{Makevars.win}.\\
  \emph{Note}: Replace \texttt{\textbackslash{}} in the \texttt{Makevars.win} file into \texttt{/} in order for R to recognize the path.

  \begin{itemize}
  \tightlist
  \item
    For example, the \texttt{-I"\$\{CPLEX\_STUDIO\_DIR\}\textbackslash{}cplex\textbackslash{}include"} should be replaced with path such as:\\
    \texttt{-I"C:/Program Files/IBM/ILOG/CPLEX\_Studio1210/cplex/include"}~\\
  \item
    The \texttt{-L"\$\{CPLEX\_STUDIO\_LIB\}"} should be replaced with path such as:\\
    \texttt{-L"C:/Program Files/IBM/ILOG/CPLEX\_Studio1210/cplex/bin/x64\_win64"}
  \end{itemize}
\item
  In command line, run line below to build package, change \texttt{\$\{Username\}} to actual name.\\
  \texttt{R CMD build -\/-no-build-vignettes -\/-no-manual -\/-md5 "C:\textbackslash{}Users\textbackslash{}\$\{Username\}\textbackslash{}Desktop\textbackslash{}cplexAPI"}~\\
  a new package cplexAPI\_1.4.0.tar.gz will be built under the default path (for example, \texttt{C:\textbackslash{}Users\textbackslash{}\$\{Username\}})
\item
  In command line, run line below to install package.\\
  \texttt{R CMD INSTALL -\/-build -\/-no-multiarch .\textbackslash{}cplexAPI\_1.4.0.tar.gz}~\\
  If you see \texttt{DONE (cplexAPI)}, then the package installation is successful.

  \begin{itemize}
  \tightlist
  \item
    \emph{Note}: if error occurs relating to \texttt{\_\_declspec(dllimport deprecated)}, you need to go to \texttt{C:\textbackslash{}Program Files\textbackslash{}IBM\textbackslash{}ILOG\textbackslash{}CPLEX\_Studio1210\textbackslash{}cplex\textbackslash{}include\textbackslash{}ilcplex} (or other installation path), open the \texttt{file cpxconst.h}, go to the line indicated in the error message or search for \texttt{\_\_declspec(dllimport deprecated)}, add \texttt{\_} to \texttt{\_\_declspec(dllimport deprecated)}, making it to \texttt{\_\_declspec(dllimport\_deprecated)}. Save file and repeat \emph{step 4}.
  \end{itemize}
\item
  To take a short venture using CPLEX in R, refer to \textbf{Package cplexAPI -- Quick Start} in \url{https://cran.r-project.org/web/packages/cplexAPI/index.html}.
\end{enumerate}

\hypertarget{using-netid}{%
\section{Using NetID}\label{using-netid}}

This section will use yeast negative-mode dataset and mouse liver negative-mode dataset as examples to walk through the NetID workflow.

\begin{itemize}
\tightlist
\item
  \emph{Note 1: If other El-MAVEN version was used, check the ``raw\_data.csv'' for the column number where the first sample is located, and specify that in the NetID\_run\_script.R file. For example, In El-MAVEN (version 7.0), first\_sample\_col\_num is set at 15 as default. If El-MAVEN (version 12.0) is used, first\_sample\_col\_num should be set at 16.}
\item
  \emph{Note 2: for more advanced uses, scoring and other parameters can be edited in NetID\_function.R and NetID\_run\_script.R. Read the manuscript method section for detailed explanation on parameters.}
\end{itemize}

\hypertarget{yeast-negative-mode-dataset}{%
\subsection{Yeast negative-mode dataset}\label{yeast-negative-mode-dataset}}

In the \texttt{Sc\_neg} folder, file \texttt{raw\_data.csv} is the output from \textbf{Elmaven} recording MS information, and is the input file for \textbf{NetID}. MS2 is not collected for this dataset.

\hypertarget{running-the-code}{%
\subsubsection{Running the code}\label{running-the-code}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Open \texttt{code folder} \(\rightarrow\) \texttt{NetID\_run\_script.R}
\item
  In the \texttt{\# Setting path \#\#\#\# section}, set work\_dir as \texttt{"../Sc\_neg/"}.
\end{enumerate}

\begin{verbatim}
# Setting path ####
{
  setwd(dirname(rstudioapi::getSourceEditorContext()$path))
  source("NetID_function.R")
  
  work_dir = "../Sc_neg/"
  setwd(work_dir)
  printtime = Sys.time()
  timestamp = paste(unlist(regmatches(printtime, gregexpr("[[:digit:]]+", printtime))),collapse = '')
}
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  In the \texttt{\# Read data and files \#\#\#\# section}, set filename as \texttt{"raw\_data.csv"}, set MS2\_folder as \texttt{""}.\\
  set \texttt{ion\_mode} as \texttt{-1} if negative ionization data is loaded, and \texttt{1} if positive ionization data loaded.
\end{enumerate}

\begin{verbatim}
# Read data and files ####
{
  Mset = list()
  # Read in files 
  Mset = read_files(filename = "raw_data.csv",
                    LC_method = "Hilic_25min_QE", # "Hilic_Rutgers_QEPlus" "Hilic_25min_QE", lipids is empty
                    ion_mode = -1 # 1 for pos mode and -1 for neg mode
                    )
  Mset = read_MS2data(Mset,
                      MS2_folder = "") # MS2
}
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Keep all other parameters as default, and run all lines.
\end{enumerate}

\hypertarget{expected-outputs}{%
\subsubsection{Expected outputs}\label{expected-outputs}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  In the console, error message should not occur. If optimization step is successful, you will see messages in the following format.
\end{enumerate}

\begin{verbatim}
"Optimization ended successfull - integer optimal, tolerance - OBJ_value = 2963.71 (bestobjective - bestinteger) / (1e-10 + |bestinteger|) = 0.000048268"
95.74 sec elapsed
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Three files will be generated in the \texttt{Sc\_neg} folder. Expected run time on a ``normal'' desktop computer should be within an hour.

  \begin{itemize}
  \tightlist
  \item
    \texttt{NetID\_output.csv} contains the annotation information for each peak.\\
  \item
    \texttt{NetID\_output.RData} contains node, edge and network information. The file will be used for network visualization in Shiny R app.\\
  \item
    \texttt{.RData} records the environmental information after running codes. The file is mainly used for development and debugging.
  \end{itemize}
\end{enumerate}

\hypertarget{your-own-dataset}{%
\subsection{Your own dataset}\label{your-own-dataset}}

\hypertarget{ms1-dataset-preparation}{%
\subsubsection{MS1 dataset preparation}\label{ms1-dataset-preparation}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  File conversion. Use software ProteoWizard40 (version 3.0.11392) to convert LC-MS raw data files (.raw) into mzXML format. A command line script specifies the conversion parameter. Assuming the raw data are in D:/MS data/test. Type in the scripts below.

\begin{verbatim}
D:
cd D:/MS data/test
"C:\Program Files\ProteoWizard\ProteoWizard 3.0.11392\msconvert.exe" *.raw --filter "peakPicking true 1-" --simAsSpectra --srmAsSpectra --mzXML 
\end{verbatim}

  If \textbf{ProteoWizard} is installed in location other than \texttt{C:\textbackslash{}Program Files\textbackslash{}ProteoWizard\textbackslash{}ProteoWizard 3.0.11392\textbackslash{}msconvert.exe}, specify your path to where you can find the \texttt{msconvert.exe} file.\\
  Expected outputs will be \texttt{.mzXML} files from \texttt{.raw} data.
\item
  \textbf{El-MAVEN (version 7.0)} is used to generate a peak table containing m/z, retention time, intensity for peaks. Detailed guides for peak picking can be found in \url{https://elucidatainc.github.io/ElMaven/faq/}.\\
  After peak picking and a peak table tab has shown up, click \texttt{export to CSV}. Choose \texttt{export all groups}. In the pop-up saved window, choose format \texttt{Groups Summary Matrix Format Comma Delimited}. Save to the desired path.
\item
  Under the \texttt{NetID} folder, create a new folder \texttt{NetID\_test}, copy the csv file from \emph{step 2} into the folder, and change the filename into \texttt{raw\_data.csv}.
\end{enumerate}

\hypertarget{ms2-dataset-preparation}{%
\subsubsection{MS2 dataset preparation}\label{ms2-dataset-preparation}}

NetID currently utilizes targeted MS2 data for better MS2 quality, and will incorporate data-dependent MS2 data in the future.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Prepare MS2 inclusion list\\
  For targeted MS2 analysis, from the peak list generated in step 1, select the peaks (m/z, RT) that you want to perform MS2, and arrange them into multiple csv files that will serve as the inclusion lists to set up the PRM method on Thermo QExactive instrument. Instruction can be found in \url{https://proteomicsresource.washington.edu/docs/protocols05/PRM_QExactive.pdf}.\\
  \emph{Note}: Arrange the parent ions so as to avoid to perform many PRMs at same time. An example is shown below with the start and End time set as RT-1.5 and RT+1.5 (min) to have good chromatogram coverage.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readr)}
\FunctionTok{read\_csv}\NormalTok{(}\StringTok{"example.csv"}\NormalTok{)}
\DocumentationTok{\#\# }
\DocumentationTok{\#\# {-}{-} Column specification {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\DocumentationTok{\#\# cols(}
\DocumentationTok{\#\#   Mass = col\_double(),}
\DocumentationTok{\#\#   Formula = col\_logical(),}
\DocumentationTok{\#\#   Formula\_type = col\_logical(),}
\DocumentationTok{\#\#   Species = col\_logical(),}
\DocumentationTok{\#\#   CS = col\_logical(),}
\DocumentationTok{\#\#   Polarity = col\_character(),}
\DocumentationTok{\#\#   Start = col\_double(),}
\DocumentationTok{\#\#   End = col\_double(),}
\DocumentationTok{\#\#   CE = col\_double(),}
\DocumentationTok{\#\#   CE\_type = col\_character(),}
\DocumentationTok{\#\#   MSXID = col\_logical(),}
\DocumentationTok{\#\#   Comment = col\_character()}
\DocumentationTok{\#\# )}
\DocumentationTok{\#\# \# A tibble: 16 x 12}
\DocumentationTok{\#\#     Mass Formula Formula\_type Species CS    Polarity  Start   End    CE CE\_type}
\DocumentationTok{\#\#    \textless{}dbl\textgreater{} \textless{}lgl\textgreater{}   \textless{}lgl\textgreater{}        \textless{}lgl\textgreater{}   \textless{}lgl\textgreater{} \textless{}chr\textgreater{}     \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}chr\textgreater{}  }
\DocumentationTok{\#\#  1 499.  NA      NA           NA      NA    Negative  0.456  3.46    30 NCE    }
\DocumentationTok{\#\#  2 722.  NA      NA           NA      NA    Negative  0.733  3.73    30 NCE    }
\DocumentationTok{\#\#  3 403.  NA      NA           NA      NA    Negative  1.06   4.06    30 NCE    }
\DocumentationTok{\#\#  4 211.  NA      NA           NA      NA    Negative  1.20   4.20    30 NCE    }
\DocumentationTok{\#\#  5 328.  NA      NA           NA      NA    Negative  1.40   4.40    30 NCE    }
\DocumentationTok{\#\#  6 149.  NA      NA           NA      NA    Negative  1.59   4.59    30 NCE    }
\DocumentationTok{\#\#  7 151.  NA      NA           NA      NA    Negative  2.69   5.69    30 NCE    }
\DocumentationTok{\#\#  8 335.  NA      NA           NA      NA    Negative  2.70   5.70    30 NCE    }
\DocumentationTok{\#\#  9 143.  NA      NA           NA      NA    Negative  4.07   7.07    30 NCE    }
\DocumentationTok{\#\# 10  89.0 NA      NA           NA      NA    Negative  5.67   8.67    30 NCE    }
\DocumentationTok{\#\# 11 283.  NA      NA           NA      NA    Negative  6.92   9.92    30 NCE    }
\DocumentationTok{\#\# 12 202.  NA      NA           NA      NA    Negative  8.79  11.8     30 NCE    }
\DocumentationTok{\#\# 13 160.  NA      NA           NA      NA    Negative 10.3   13.3     30 NCE    }
\DocumentationTok{\#\# 14 216.  NA      NA           NA      NA    Negative 11.4   14.4     30 NCE    }
\DocumentationTok{\#\# 15 125.  NA      NA           NA      NA    Negative 12.0   15.0     30 NCE    }
\DocumentationTok{\#\# 16 230.  NA      NA           NA      NA    Negative 12.9   15.9     30 NCE    }
\DocumentationTok{\#\# \# ... with 2 more variables: MSXID \textless{}lgl\textgreater{}, Comment \textless{}chr\textgreater{}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Instrument setup\\
  Set up the QExactive instrument so that it contains both ``Full MS'' and ``PRM'' scan events. For PRM setup, use the above file as inclusion list to perform targeted MS2 analysis. We typically use the following setting for MS2 analysis: resolution 17500, AGC target 1e6, Maximum IT 500 ms, isolation window 1.5 m/z. For a total of 1500 parent ions and 15 parent ions for each method, it requires a total of 100 runs, or \textasciitilde42 hours using a 25-min LC method.
\item
  MS2 file conversion.\\
  \textbf{RawConverte}r (version 1.2.0.1, \url{http://fields.scripps.edu/rawconv/}) is used to convert the \texttt{.raw} file into \texttt{.mzXML} file that contains MS2 information. Keep the default parameters except setting \texttt{Environment Type} as \texttt{Data Independent}, and \texttt{Output Formats} as \texttt{mzXML}.
\item
  MS2 reading and cleaning.\\
  A matlab code is used for MS2 reading and cleaning, which can be found in \textbf{CodeOcean} as a published capsule (\url{https://codeocean.com/capsule/1048398/tree/v1}). The \texttt{csv} files from \emph{1} paired with the MS2 data files in \texttt{mzXML} format from \emph{3} are the required input data. Refer to capsule description and \texttt{readme.md} file for more details of how the code works. In Brief,

  \begin{itemize}
  \tightlist
  \item
    Prepare filename. Filenames for both csv and mzXML files should be named as \texttt{prefixNNN}, where prefix is the given file name and NNN is the 3 digits number in continuous order (e.g.~\texttt{M001.csv}, \texttt{M002.csv},\ldots{} and \texttt{M001.mzXML}, \texttt{M002.mzXML},\ldots{} in the \texttt{/data} folder).\\
  \item
    Duplicate the capsule to your own account so you can edit and use the capsule. Upload your own files and remove the previous files in \texttt{/data} folder.\\
  \item
    Specify the prefix and the range of numbers at the beginning section of the main code \texttt{Main\_example.m}.\\
  \item
    Set the main code as file to run in Code Ocean using the dropdown menu next to main code.\\
  \item
    Click \texttt{reproducible run} to perform the batch processing.\\
  \item
    The resulting output files in \texttt{.xlsx} format with the same filenames will appear in the timeline. Each \texttt{xlsx} file contains multiple tabs of cleaned MS2 spectra. The names of the tabs correspond to the row numbers of the \texttt{csv} file specifying the individual parent peak information.
  \end{itemize}
\item
  Save files to folders.\\
  Back to the \texttt{NetID\_test} folder, create a new folder \texttt{MS2}, download all \texttt{xlsx} files from \emph{4} into the folder.
\end{enumerate}

\hypertarget{running-the-code-1}{%
\subsubsection{Running the code}\label{running-the-code-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Open \texttt{code} folder \(\rightarrow\) \texttt{NetID\_run\_script.R}.
\item
  In the \texttt{\# Setting path \#\#\#\# section}, set \texttt{work\_dir} as \texttt{"../NetID\_test/"}.
\item
  In the \texttt{\# Read data and files \#\#\#\#} section,\\
  set \texttt{filename} as \texttt{raw\_data.csv}, set \texttt{MS2\_folder} as \texttt{MS2}.\\
  set \texttt{LC\_method} to specify column to read for the retention time of known standards. (In folder \texttt{NetID} \(\rightarrow\) \texttt{dependent} \(\rightarrow\) \texttt{known\_library.csv}, update the retention time info as needed.)\\
  set \texttt{ion\_mode} as \texttt{-1} if negative ionization data is loaded, and \texttt{1} if positive ionization data loaded.
\item
  Keep all other parameters as default, and run all lines.
\end{enumerate}

\hypertarget{expected-outputs-1}{%
\subsubsection{Expected outputs}\label{expected-outputs-1}}

Similar to the \texttt{demo} file, the console will print out message indicating optimization step is successful, and three files \texttt{NetID\_output.csv}, \texttt{NetID\_output.RData} and \texttt{.RData} will be generated in the \texttt{NetID\_test} folder

\hypertarget{netid-visualization}{%
\section{NetID Visualization}\label{netid-visualization}}

This section provides instruction to visualize and explore \textbf{NetID} output results in either \textbf{Cytoscape} software or interactive \textbf{Shiny R app}. After running \textbf{NetID} algorithm, it will export one \texttt{.R} and two \texttt{.csv}files (\texttt{cyto\_node.csv} and \texttt{cyto\_edges.csv}), storing the nodes and edges of the output network.

\hypertarget{cytoscape}{%
\subsection{Cytoscape}\label{cytoscape}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  install \textbf{Cytoscape}
  Download \textbf{Cytoscape} (\url{https://cytoscape.org/download.html}) and follow installation instruction to install onto your computer.
\item
  Load the example \textbf{NetID} output into \textbf{Cytoscape}

  \begin{itemize}
  \tightlist
  \item
    Run \textbf{Cytoscape}, click \texttt{import network from file system}, and load \texttt{cyto\_edges.csv}, set \texttt{edge\_id} column as the \texttt{key}, set \texttt{node1}as \texttt{source node}, set \texttt{node2} column as \texttt{target node}, and the rest columns as \texttt{edge attribute}.\\
  \item
    Click \texttt{import table from file}, load \texttt{cyto\_node.csv}, set \texttt{node\_id} column as the \texttt{key}, and the rest columns as \texttt{node attribute}.
  \item
    Select \texttt{subnetwork}, set \texttt{styles}, and explore the network with various functionalities inside \textbf{Cytoscape}.
  \end{itemize}
\item
  Explore in Cytoscape
\item
  Export\\
  The network as well as the curated subnetworks can be exported for future analysis or sharing with others. An example network file \texttt{example.cys} is included along with the two \texttt{.csv} files, which is created using \textbf{Cytoscape} version 3.8.2
\end{enumerate}

\hypertarget{shiny-app}{%
\subsection{Shiny App}\label{shiny-app}}

This part provides instruction to visualize and explore \textbf{NetID} output results in the interactive \textbf{Shiny R app}. A 21-inch or larger screen is recommended for best visualization.

\hypertarget{runing-shiny-app}{%
\subsubsection{Runing Shiny App}\label{runing-shiny-app}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Open \texttt{code} folder \(\rightarrow\) \texttt{R\_shiny\_App.R}.
\item
  In the \texttt{\# Read in files \#\#\#\# section}, set datapath as \texttt{../Sc\_neg/}
\item
  Keep all other parameters as default, and run all lines.
\item
  A Shiny app will pop up.
\end{enumerate}

\hypertarget{searching-peaks-of-interest}{%
\subsubsection{Searching peaks of interest}\label{searching-peaks-of-interest}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  On the left panel, you can enter a m/z or a formula to search your peak of interest. For example, 180.0631 or C6H12O6 will automatically update the data table on the right. Enter 0 to restore full list for the data table.
\item
  Change ionization and ppm window to adjust calculated m/z.
\item
  On the right, you can explore the peak list in an interactive data table, including global text search on top right, specifying ranges for numeric column or searching text within character columns, ranking each column etc.
\end{enumerate}

\hypertarget{network-visualization}{%
\subsubsection{Network Visualization}\label{network-visualization}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Peak ID, formula and class determines the center node for the network graph. Peak ID will be automatically updated by the first line in the data table if a m/z or formula is given. Alternatively, you can manually enter Peak ID.
\item
  The degree parameter controls how far the network expands from the center node. Degree 1 means only nodes directly connected to the center node will be shown and degree 2 means nodes connected to degree 1 will be shown, etc.
\item
  Biochemical graph shows biochemical connections. Abiotic graph shows abiotic connections. Node labels and Edge labels determines if the graph show node or edge labels. Optimized only determines whether to show only the optimal annotations or all possible annotations in the network.
\item
  When setting parameters, hit plot to see the network graph.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  A sample network graph is shown below (a different center node may give less complicated graph). You may edit the nodes or edges (top left), move figures with the arrow buttons (bottom left), and zoom in/out or center figure (bottom right).
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  You can use the ``Download plot'' button to download a html webpage to visualize the network graph independent of the Shiny app, and the ``Download csv'' button to download the information of the nodes in the network. The download buttons will appear after hitting the plot button. Note: edits within the Shiny app will not go into the html file.
\end{enumerate}

\hypertarget{possible-structures-exploration}{%
\subsubsection{Possible structures exploration}\label{possible-structures-exploration}}

A figure + data table is provided to explore structures of the selected node in the network graph.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The figure shows the chemical structure of the annotated metabolites. If the node is annotated as a putative metabolite, only the known parts of the putative metabolite will be shown.\\
  Scroll left or right, or select the entry number, to visualize different annotations. Right click and select to save image.
\item
  In the data table, class has 3 possible entries: Metabolite if it is documented in database such as HMDB library; Putative metabolite if it is transformed from a metabolite through a biotransformation edge; and Artifact if it is transformed by an abiotic edge.\\
  Use the download button to download the data table
\end{enumerate}

\hypertarget{troubleshooting}{%
\section{Troubleshooting}\label{troubleshooting}}

\hypertarget{failing-to-install-package-lc8}{%
\subsection{\texorpdfstring{Failing to install package \texttt{lc8}}{Failing to install package lc8}}\label{failing-to-install-package-lc8}}

Reinstall the packages \texttt{devtools} and \texttt{digest}.

\hypertarget{cannot-find-cplexapi-even-if-the-installation-seems-successful}{%
\subsection{\texorpdfstring{Cannot find \texttt{cplexAPI} even if the installation seems successful}{Cannot find cplexAPI even if the installation seems successful}}\label{cannot-find-cplexapi-even-if-the-installation-seems-successful}}

Check \textbf{R} version used in \textbf{RStudio} to see if \texttt{cplexAPI} is installed under the same R version library. Which R library \texttt{cplexAPI} goes to depends on the R path specified in \texttt{Environment Variables}.

\hypertarget{add-r-to-path}{%
\subsection{\texorpdfstring{Add \textbf{R} to \texttt{PATH}}{Add R to PATH}}\label{add-r-to-path}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Go to \texttt{Environment Variables}:\\
  search \texttt{PATH} in \texttt{windows} \(\rightarrow\) open \texttt{edit Environment Variables} \(\rightarrow\) \texttt{Environment Variables}
  or\\
  \texttt{control panel} \(\rightarrow\) \texttt{system and security} \(\rightarrow\) \texttt{System} \(\rightarrow\) \texttt{Advanced system Settings} (on your left) \(\rightarrow\) \texttt{Advanced} \(\rightarrow\) \texttt{Environment Variables}
\item
  In the lower Panel select the \texttt{Path Variable} and select \texttt{Edit}, add the R path (\texttt{C:\textbackslash{}Program Files\textbackslash{}R\textbackslash{}R-4.0.3\textbackslash{}bin\textbackslash{}x64}, if installed at default location) to the \texttt{Path Variable}.
\item
  You may need to restart computer for the R path to take effect.
\end{enumerate}

\hypertarget{add-rtools40-to-path}{%
\subsection{\texorpdfstring{Add \textbf{Rtools40} to \texttt{PATH}}{Add Rtools40 to PATH}}\label{add-rtools40-to-path}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Add the path \texttt{C:\textbackslash{}Rtools\textbackslash{}bin} to the \texttt{Path Variable}in \texttt{Environment Variables}
\item
  Run the line in \textbf{R}:\\
\end{enumerate}

\begin{verbatim}
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
Use the line below in R console to check for successfully adding Rtools40
Sys.which("make")
\end{verbatim}

Expected output: \texttt{\#\# "C:\textbackslash{}\textbackslash{}rtools40\textbackslash{}\textbackslash{}usr\textbackslash{}\textbackslash{}bin\textbackslash{}\textbackslash{}make.exe}


\end{document}
